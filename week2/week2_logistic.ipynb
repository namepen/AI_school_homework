{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## week2 Logistic regression(2-class)\n",
    "\n",
    "* 참고 사이트\n",
    "cross entropy gradient, https://kakalabblog.wordpress.com/2017/04/04/cross-entropy-%EC%A0%95%EB%A6%AC/\n",
    "\n",
    "https://madalinabuzau.github.io/2016/11/29/gradient-descent-on-a-softmax-cross-entropy-cost-function.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 실습에 필요한 라이브러리를 불러옵니다.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.623660</td>\n",
       "      <td>78.024693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.286711</td>\n",
       "      <td>43.894998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.847409</td>\n",
       "      <td>72.902198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.182599</td>\n",
       "      <td>86.308552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.032736</td>\n",
       "      <td>75.344376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1  2\n",
       "0  34.623660  78.024693  0\n",
       "1  30.286711  43.894998  0\n",
       "2  35.847409  72.902198  0\n",
       "3  60.182599  86.308552  1\n",
       "4  79.032736  75.344376  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터를 불러옵니다.\n",
    "data = pd.read_csv('data/data.txt', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "X = data[:, [0,1]]\n",
    "y = data[:, 2]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#배열 \n",
    "x_1 = np.zeros((X.shape[0], 1))\n",
    "x_2 = np.concatenate((x_1, X), axis=1)\n",
    "x_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "(100,)\n",
      "[   0.         4483.1353618  4437.38412496]\n",
      "[  0.           0.           0.         146.49115148 154.37711249\n",
      "   0.         157.61809042 121.57875911 163.51935642 127.96621327\n",
      "   0.           0.         158.78901668 167.08328072   0.\n",
      " 143.17840229 121.81061379   0.         163.58864745 124.55474738\n",
      "   0.         155.47614168   0.           0.         146.89645145\n",
      " 132.22547162 125.01180968   0.           0.           0.\n",
      " 134.18717676 142.45650337   0.         121.47826489   0.\n",
      "   0.           0.         145.08504946   0.           0.\n",
      " 140.21043988   0.         160.01228937   0.           0.\n",
      "   0.         147.65123493 184.49942161 158.84188792 180.26126704\n",
      " 154.10793729 160.27155793 133.93731592   0.           0.\n",
      "   0.         166.50720668   0.         144.07326259 150.2500243\n",
      " 161.15554814   0.           0.           0.           0.\n",
      "   0.         137.99273647   0.         172.39563483 127.7381126\n",
      "   0.         142.07100844 168.57408719 133.55288384 134.69940453\n",
      " 172.19710973 135.7401341  126.26801933   0.           0.\n",
      " 158.71768532 140.52881353 133.90861065 116.7529883  171.3269039\n",
      " 154.06282889   0.         165.902241   175.28285152   0.\n",
      " 171.25343622 177.95734274   0.         159.33782927 135.20409032\n",
      " 131.86944854 129.36555175 168.09041828 120.27195557 164.3057059 ]\n"
     ]
    }
   ],
   "source": [
    "#np.sum axis 설정 \n",
    "print(x_1.shape)\n",
    "print(y.shape)\n",
    "print(np.sum(x_2.T* y, axis=1))\n",
    "print(np.sum(x_2.T* y, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 학습합니다.\n",
    "class LogisticRegression:\n",
    "    def __init__(self, lr = 0.01, num_iter = 100, fit_intercept = True):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "        \n",
    "    def add_intercept(self, X): #beta_0에 대한 추정을 하기 위해 1인 배열 추가, y = X^T * B(X = [1, X], B = [beta_0, beta_1]\n",
    "        intercept = np.ones((X.shape[0], 1)) #1로 초기화하는 2차원 배열 생성\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    #np.concatenate : 여러개의 배열을 하나로 합치는 함수, axis = 0(y축), axis=1(x축)\n",
    "    \n",
    "    def sigmoid(self, z): #sigmoid함수 선언\n",
    "            self.z = z\n",
    "            sigmoid = 1 / (1+ np.exp(-z))\n",
    "            return sigmoid\n",
    "    \n",
    "    def loss(self, h, y): #cross-entropy 방식의 loss 선언\n",
    "            loss = np.sum(-(y*np.log(h) + (1-y)*np.log(1-h))) / X.shape[0]\n",
    "            return loss\n",
    "    \n",
    "    def fit(self, X, y): #모델 학습 과정\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "            print(X.shape)\n",
    "            \n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "            \n",
    "        for i in range(self.num_iter):\n",
    "            z = np.dot(X, self.theta) # y_pred = X*W\n",
    "            h = self.sigmoid(z)\n",
    "            gradient = np.sum(X.T * (h-y), axis=1) / X.shape[0]\n",
    "            self.theta = self.theta - self.lr * gradient\n",
    "            print(self.theta)\n",
    "            \n",
    "            z = np.dot(X, self.theta)\n",
    "            h = self.sigmoid(z)\n",
    "            loss = self.loss(h, y)\n",
    "            \n",
    "        return z, h, loss\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "    \n",
    "        return self.sigmoid(np.dot(X, self.theta))\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return self.predict_prob(X).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "[0.001      0.12009217 0.11262842]\n",
      "[-0.00299992 -0.08803412 -0.10584942]\n",
      "[0.00299971 0.36026435 0.33787159]\n",
      "[-0.00100029  0.15213514  0.11939003]\n",
      "[-0.00500027 -0.05599341 -0.09909066]\n",
      "[0.00099766 0.39222165 0.34455138]\n",
      "[-0.00300234  0.18409245  0.12606982]\n",
      "[-0.00700234 -0.0240366  -0.09241153]\n",
      "[-0.00101746  0.42339398  0.35062696]\n",
      "[-0.00501746  0.21526477  0.13214539]\n",
      "[-0.00901746  0.00713561 -0.08633612]\n",
      "[-0.00315988  0.4455214   0.35082561]\n",
      "[-0.00715988  0.23739219  0.13234404]\n",
      "[-0.01115988  0.02926301 -0.0861375 ]\n",
      "[-0.00576927  0.43156684  0.32908994]\n",
      "[-0.00976927  0.22343763  0.11060837]\n",
      "[-0.01376926  0.01530852 -0.10787307]\n",
      "[-0.00786653  0.45653293  0.331599  ]\n",
      "[-0.01186653  0.24840372  0.11311743]\n",
      "[-0.01586653  0.04027455 -0.10536409]\n",
      "[-0.01043864  0.44390591  0.31268249]\n",
      "[-0.01443864  0.23577671  0.09420093]\n",
      "[-0.01843864  0.02764763 -0.12428046]\n",
      "[-0.01255658  0.46693648  0.31443785]\n",
      "[-0.01655658  0.25880728  0.09595628]\n",
      "[-0.02055657  0.05067813 -0.1225252 ]\n",
      "[-0.01513562  0.45269763  0.2958637 ]\n",
      "[-0.01913562  0.24456843  0.07738213]\n",
      "[-0.02313561  0.03643943 -0.14109913]\n",
      "[-0.01724952  0.47578864  0.2979079 ]\n",
      "[-0.02124952  0.26765944  0.07942633]\n",
      "[-0.02524952  0.05953032 -0.1390551 ]\n",
      "[-0.0198088   0.46238938  0.28068929]\n",
      "[-0.0238088   0.25426018  0.06220772]\n",
      "[-0.02780879  0.0461313  -0.15627336]\n",
      "[-0.02193751  0.48407126  0.28220538]\n",
      "[-0.02593751  0.27594206  0.06372381]\n",
      "[-0.02993751  0.067813   -0.15475754]\n",
      "[-0.0244829   0.47124769  0.26593304]\n",
      "[-0.0284829   0.26311848  0.04745148]\n",
      "[-0.03248288  0.05498978 -0.17102931]\n",
      "[-0.02662437  0.49170344  0.26700107]\n",
      "[-0.03062437  0.28357424  0.0485195 ]\n",
      "[-0.03462437  0.07544528 -0.16996168]\n",
      "[-0.02915136  0.47996656  0.2517803 ]\n",
      "[-0.03315136  0.27183735  0.03329873]\n",
      "[-0.03715133  0.06370894 -0.18518157]\n",
      "[-0.03131029  0.49881443  0.25220367]\n",
      "[-0.03531029  0.29068523  0.0337221 ]\n",
      "[-0.03931028  0.08255644 -0.1847588 ]\n",
      "[-0.03381602  0.48850284  0.23809097]\n",
      "[-0.03781602  0.28037363  0.0196094 ]\n",
      "[-0.04181598  0.07224568 -0.19887006]\n",
      "[-0.0359959   0.5054514   0.23772602]\n",
      "[-0.0399959   0.29732219  0.01924445]\n",
      "[-0.04399587  0.08919372 -0.19923588]\n",
      "[-0.03847738  0.4968934   0.22480047]\n",
      "[-0.04247738  0.28876419  0.0063189 ]\n",
      "[-0.04647732  0.08063704 -0.21215899]\n",
      "[-0.04068157  0.51165592  0.22350918]\n",
      "[-0.04468157  0.30352671  0.00502761]\n",
      "[-0.04868153  0.09539887 -0.2134515 ]\n",
      "[-0.04313622  0.50513034  0.2118421 ]\n",
      "[-0.04713622  0.29700114 -0.00663947]\n",
      "[-0.05113612  0.08887543 -0.2251143 ]\n",
      "[-0.04536726  0.51748872  0.20951999]\n",
      "[-0.04936726  0.30935952 -0.00896158]\n",
      "[-0.05336718  0.10123301 -0.22743789]\n",
      "[-0.04779374  0.51316078  0.19913779]\n",
      "[-0.05179374  0.30503158 -0.01934378]\n",
      "[-0.05579355  0.09690869 -0.23781221]\n",
      "[-0.05005235  0.5230524   0.19575393]\n",
      "[-0.05405235  0.31492319 -0.02272764]\n",
      "[-0.05805218  0.10679976 -0.24119697]\n",
      "[-0.05245148  0.52089449  0.18659877]\n",
      "[-0.05645148  0.31276529 -0.0318828 ]\n",
      "[-0.06045112  0.10464828 -0.25033706]\n",
      "[-0.05473563  0.52849093  0.1822348 ]\n",
      "[-0.05873563  0.32036172 -0.03624677]\n",
      "[-0.06273524  0.11224573 -0.25469803]\n",
      "[-0.05711092  0.5282351   0.17414627]\n",
      "[-0.06111092  0.3201059  -0.0443353 ]\n",
      "[-0.06511016  0.11200203 -0.2627563 ]\n",
      "[-0.05941577  0.53394555  0.16900471]\n",
      "[-0.06341577  0.32581635 -0.04947686]\n",
      "[-0.06741483  0.11771901 -0.26788046]\n",
      "[-0.06177284  0.53512163  0.16175023]\n",
      "[-0.06577284  0.32699242 -0.05673134]\n",
      "[-0.06977117  0.1189196  -0.27507092]\n",
      "[-0.06409195  0.53947953  0.15611647]\n",
      "[-0.06809195  0.33135033 -0.0623651 ]\n",
      "[-0.07208961  0.12330015 -0.28064372]\n",
      "[-0.06643698  0.5415354   0.14947372]\n",
      "[-0.07043698  0.3334062  -0.06900785]\n",
      "[-0.07443308  0.12540877 -0.28714443]\n",
      "[-0.06876409  0.54501674  0.14366649]\n",
      "[-0.07276409  0.33688754 -0.07481508]\n",
      "[-0.0767583   0.12895426 -0.29277627]\n",
      "[-0.07110202  0.54743516  0.1375328 ]\n",
      "[-0.07510202  0.33930596 -0.08094876]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 5.35690945,  6.64811353,  6.18679445, 13.35864178, 20.6421419 ,\n",
       "        10.66318185, 12.84627256, 21.61275116, 18.66908248, 25.04948231,\n",
       "        29.35700558, 22.90018274, 21.66105102, 15.55050874,  7.18540607,\n",
       "        11.01637268, 19.09153341, 19.20109787, 16.37843207, 22.19304235,\n",
       "        19.31690957, 25.02638478, 13.11683508,  7.95454734, 20.78177904,\n",
       "        15.3910969 , 23.50564848, 28.37829841, 16.83608533,  7.82383217,\n",
       "        14.85754798, 24.28487251, 12.49534274, 11.96370959,  7.81657443,\n",
       "        14.23626518,  3.42927052, 15.15112504, 21.93602039,  5.43321016,\n",
       "        23.83541314, 13.62238771, 26.66237202, 24.58510919, 13.53641316,\n",
       "        16.82314952, 20.41345029, 26.07887393, 13.15334152, 23.81358394,\n",
       "        21.04723802, 28.67086149, 27.13552181,  6.75026188, 12.95578976,\n",
       "        11.90849224, 27.48238398,  3.23995173, 19.46570845, 17.93514628,\n",
       "        18.56491713,  8.09143373, 15.83398564,  6.10954552,  9.70205288,\n",
       "        19.18305137,  5.75703326, 12.37562909, 19.70755432, 17.63527918,\n",
       "         7.52228799, 15.33725211, 16.68298965, 14.52166895, 13.74933725,\n",
       "        27.93888322,  8.79993406, 10.90893769, 16.99682511, 24.36677265,\n",
       "        24.44338218, 28.40391331, 17.37639716, 14.52872438, 19.83070541,\n",
       "        16.22792185,  7.81896232, 18.21517715, 18.78287604, 12.76767118,\n",
       "        25.60573078, 23.53090151, 15.87092124, 18.33260324, 26.73841834,\n",
       "        24.33694384,  7.21359569, 28.05578761, 13.44593542, 18.04947614]),\n",
       " array([0.99530667, 0.99870521, 0.99794781, 0.99999842, 1.        ,\n",
       "        0.99997661, 0.99999736, 1.        , 0.99999999, 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.99999982, 0.99924301,\n",
       "        0.99998357, 0.99999999, 1.        , 0.99999992, 1.        ,\n",
       "        1.        , 1.        , 0.99999799, 0.99964906, 1.        ,\n",
       "        0.99999979, 1.        , 1.        , 0.99999995, 0.99960007,\n",
       "        0.99999965, 1.        , 0.99999626, 0.99999363, 0.99959716,\n",
       "        0.99999934, 0.96860689, 0.99999974, 1.        , 0.99564996,\n",
       "        1.        , 0.99999879, 1.        , 1.        , 0.99999868,\n",
       "        0.99999995, 1.        , 1.        , 0.99999806, 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.9988308 , 0.99999764,\n",
       "        0.99999327, 1.        , 0.96231036, 1.        , 0.99999998,\n",
       "        0.99999999, 0.99969394, 0.99999987, 0.99778336, 0.99993885,\n",
       "        1.        , 0.99684948, 0.99999578, 1.        , 0.99999998,\n",
       "        0.9994594 , 0.99999978, 0.99999994, 0.99999951, 0.99999893,\n",
       "        1.        , 0.99984928, 0.99998171, 0.99999996, 1.        ,\n",
       "        1.        , 1.        , 0.99999997, 0.99999951, 1.        ,\n",
       "        0.99999991, 0.99959812, 0.99999999, 0.99999999, 0.99999715,\n",
       "        1.        , 1.        , 0.99999987, 0.99999999, 1.        ,\n",
       "        1.        , 0.99926404, 1.        , 0.99999855, 0.99999999]),\n",
       " 5.264256705792926)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 출력합니다.\n",
    "plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color='b', label='0')\n",
    "plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='r', label='1')\n",
    "plt.legend()\n",
    "\n",
    "x1_min, x1_max = X[:,0].min(), X[:,0].max(),\n",
    "x2_min, x2_max = X[:,1].min(), X[:,1].max(),\n",
    "xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max), np.linspace(x2_min, x2_max))\n",
    "\n",
    "grid = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "probs = model.predict_prob(grid).reshape(xx1.shape)\n",
    "plt.contour(xx1, xx2, probs, [0.5], linewidths=1, colors='black');\n",
    "\n",
    "plt.savefig(\"binary_classification.png\") \n",
    "#eu.send_image(\"binary_classification.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 실습에 필요한 라이브러리를 불러옵니다. 원본 실습코드\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터를 불러옵니다.\n",
    "data = pd.read_csv('data/data.txt', header=None)\n",
    "data = np.array(data)\n",
    "X = data[:, [0,1]]\n",
    "y = data[:, 2]\n",
    "\n",
    "\n",
    "# Logistic 회귀 모델을 구현합니다.\n",
    "class LogisticRegression:\n",
    "    def __init__(self, lr=0.01, num_iter=300000, fit_intercept=True):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "    \n",
    "    def add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    # sigmoid 함수를 작성하세요.\n",
    "    def sigmoid(self, z):\n",
    "        return None\n",
    "    \n",
    "    # loss 함수를 작성하세요.\n",
    "    def loss(self, h, y):\n",
    "        return None\n",
    "    \n",
    "    # 모델을 학습하는 fit 함수를 작성하세요.\n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "        \n",
    "        self.theta = None\n",
    "        \n",
    "        for i in range(self.num_iter):\n",
    "            z = None\n",
    "            h = None\n",
    "            gradient = None\n",
    "            self.theta = None\n",
    "            \n",
    "            z = None\n",
    "            h = None\n",
    "            loss = None\n",
    "        \n",
    "        return z, h, loss\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "    \n",
    "        return self.sigmoid(np.dot(X, self.theta))\n",
    "    \n",
    "    # predict_prob 함수를 이용해 predict 함수를 완성하세요.\n",
    "    def predict(self, X):\n",
    "        return self.predict_prob(X).round()\n",
    "        \n",
    "    \n",
    "# 모델을 학습합니다.\n",
    "model = None\n",
    "model.fit(X, y)\n",
    "\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color='b', label='0')\n",
    "plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='r', label='1')\n",
    "plt.legend()\n",
    "\n",
    "x1_min, x1_max = X[:,0].min(), X[:,0].max(),\n",
    "x2_min, x2_max = X[:,1].min(), X[:,1].max(),\n",
    "xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max), np.linspace(x2_min, x2_max))\n",
    "\n",
    "grid = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "probs = model.predict_prob(grid).reshape(xx1.shape)\n",
    "plt.contour(xx1, xx2, probs, [0.5], linewidths=1, colors='black');\n",
    "\n",
    "plt.savefig(\"binary_classification.png\") \n",
    "eu.send_image(\"binary_classification.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
